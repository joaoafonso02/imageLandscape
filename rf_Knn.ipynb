{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Summary\n",
    "\n",
    "### This dataset contains over 14,000 images that need to be classified into 6 distinct categories. Hereâ€™s a quick breakdown:\n",
    "- Total Images: 14,000+\n",
    "- Classes: 6 categories, each representing a unique label for classification.\n",
    "- Image Format: Likely standardized (e.g., JPEG, PNG).\n",
    "- Size and Quality: Varies, but typically consistent for training uniformity.\n",
    "- Typical Categories in Image Classification\n",
    "\n",
    "### While not specified, common image classification categories could include:\n",
    "- Natural Scenes: Different environments (e.g., mountains, forests).\n",
    "- Urban and Rural Scenes: Different landscapes (e.g., streets, buildings).\n",
    "- Objects: Specific items within scenes.\n",
    "\n",
    "#### Use Case:\n",
    "\n",
    "The model developed from this dataset would likely employ CNNs (Convolutional Neural Networks) due to their effectiveness in image feature extraction and spatial hierarchy, aiming for a high accuracy similar to 98% as mentioned in your Intel classification example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 17:15:51.100817: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob as gb\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data And Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'archive/seg_train/'\n",
    "test_path = 'archive/seg_test/'\n",
    "pred_path = 'archive/seg_pred/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- Traning Data ----------------------------------------------\n",
      "For Traning Data : Found 2271 images in folder forest\n",
      "For Traning Data : Found 2191 images in folder buildings\n",
      "For Traning Data : Found 2404 images in folder glacier\n",
      "For Traning Data : Found 2382 images in folder street\n",
      "For Traning Data : Found 2512 images in folder mountain\n",
      "For Traning Data : Found 2274 images in folder sea\n",
      "\n",
      "---------------------------------------- Test Data --------------------------------------------------\n",
      "For Test Data : Found 474 images in folder forest\n",
      "For Test Data : Found 437 images in folder buildings\n",
      "For Test Data : Found 553 images in folder glacier\n",
      "For Test Data : Found 501 images in folder street\n",
      "For Test Data : Found 525 images in folder mountain\n",
      "For Test Data : Found 510 images in folder sea\n",
      "\n",
      "---------------------------------------- Prediction Data --------------------------------------------\n",
      "For Prediction Data : Found 7301 images in folder Prediction\n"
     ]
    }
   ],
   "source": [
    "def open_folders(path, file, name = 'Traning Data'):\n",
    "    for folder in os.listdir(path + file):\n",
    "        files = gb.glob(pathname = path + file + '/' + folder + '/*.jpg')\n",
    "        print(f'For {name} : Found {len(files)} images in folder {folder}')\n",
    "\n",
    "print('-' * 40 + ' Traning Data ' + '-' * 46)\n",
    "open_folders(train_path, 'seg_train')\n",
    "print('\\n' + '-' * 40 + ' Test Data ' + '-' * 50)\n",
    "open_folders(test_path, 'seg_test', name = 'Test Data')\n",
    "print('\\n' +'-' * 40 + ' Prediction Data ' + '-' * 44)\n",
    "files = gb.glob(pathname = pred_path + 'seg_pred' + '/*.jpg')\n",
    "print(f'For Prediction Data : Found {len(files)} images in folder Prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the images are sized +/- `150x150x3`, and they need to be uniform in size for the model, which only accepts input in one specific dimension. To avoid losing significant information, we will resize them to `100x100x3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization for each folder/class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'buildings': 0, 'forest': 1, 'glacier': 2, 'mountain': 3, 'sea': 4, 'street': 5}\n",
    "\n",
    "# Get the labels for the images\n",
    "def getcode(n):\n",
    "    for x, y in code.items():\n",
    "        if n == y:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_size = 100\n",
    "def get_image_array(path, folder_name, new_size = new_size):\n",
    "    X = []\n",
    "    y = []\n",
    "    if folder_name != 'seg_pred':\n",
    "        for folder in os.listdir(path + folder_name):\n",
    "            files = gb.glob(pathname= path + folder_name + '/' + folder + '/*.jpg')\n",
    "            for file in files:\n",
    "                image = cv2.imread(file)\n",
    "                image_array = cv2.resize(image, (new_size, new_size))\n",
    "                X.append(list(image_array))\n",
    "                y.append(code[folder])\n",
    "    else :\n",
    "        files = gb.glob(pathname= path + folder_name + '/*.jpg')\n",
    "        for file in files:\n",
    "            image = cv2.imread(file)\n",
    "            image_array = cv2.resize(image, (new_size, new_size))\n",
    "            X.append(list(image_array))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- Traning Data ----------------------------------------------\n",
      "We Have 14034 Image In X_train\n",
      "We Have 14034 items In y_train \n",
      "\n",
      "---------------------------------------- Test Data --------------------------------------------------\n",
      "We Have 3000 Image In X_test\n",
      "We Have 3000 items In y_test\n",
      "\n",
      "---------------------------------------- Prediction Data --------------------------------------------\n",
      "We Have 7301 Image In X_pred\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_image_array(train_path, 'seg_train')\n",
    "X_test, y_test = get_image_array(test_path, 'seg_test')\n",
    "X_pred, _ = get_image_array(pred_path, 'seg_pred')\n",
    "\n",
    "print('-' * 40 + ' Traning Data ' + '-' * 46)\n",
    "print(f'We Have {len(X_train)} Image In X_train')\n",
    "print(f'We Have {len(y_train)} items In y_train ')\n",
    "\n",
    "print('\\n' +'-' * 40 + ' Test Data ' + '-' * 50)\n",
    "print(f'We Have {len(X_test)} Image In X_test')\n",
    "print(f'We Have {len(y_test)} items In y_test')\n",
    "\n",
    "print('\\n' +'-' * 40 + ' Prediction Data ' + '-' * 44)\n",
    "print(f'We Have {len(X_pred)} Image In X_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape  is (14034, 100, 100, 3)\n",
      "X_test shape  is (3000, 100, 100, 3)\n",
      "y_train shape  is (14034,)\n",
      "y_test shape  is (3000,)\n",
      "X_pred shape  is (7301, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = np.array(X_train) , np.array(y_train) \n",
    "X_test, y_test = np.array(X_test) , np.array(y_test) \n",
    "X_pred  = np.array(X_pred) \n",
    "\n",
    "print(f'X_train shape  is {X_train.shape}') \n",
    "print(f'X_test shape  is {X_test.shape}')\n",
    "print(f'y_train shape  is {y_train.shape}')\n",
    "print(f'y_test shape  is {y_test.shape}')\n",
    "print(f'X_pred shape  is {X_pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Augment the training data\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=64, shuffle=False):\n",
    "    augmented_images.append(X_batch)\n",
    "    augmented_labels.append(y_batch)\n",
    "    if len(augmented_images) * 64 >= len(X_train):\n",
    "        break\n",
    "\n",
    "X_train_augmented = np.vstack(augmented_images)\n",
    "y_train_augmented = np.hstack(augmented_labels)\n",
    "\n",
    "# Flatten the images for traditional ML models\n",
    "def flatten_images(X):\n",
    "    return X.reshape(X.shape[0], -1)\n",
    "\n",
    "X_train_flattened = flatten_images(X_train_augmented)\n",
    "X_test_flattened = flatten_images(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.591\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_flattened, y_train_augmented)\n",
    "rf_pred = rf_model.predict(X_test_flattened)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train_flattened, y_train_augmented)\n",
    "svm_pred = svm_model.predict(X_test_flattened)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "print(f'SVM Accuracy: {svm_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate k-NN\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_flattened, y_train_augmented)\n",
    "knn_pred = knn_model.predict(X_test_flattened)\n",
    "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
    "print(f'k-NN Accuracy: {knn_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "report_rf = classification_report(y_test, rf_pred, target_names=code.keys())\n",
    "report_svm = classification_report(y_test, svm_pred, target_names=code.keys())\n",
    "report_knn = classification_report(y_test, knn_pred, target_names=code.keys())\n",
    "print(\"Random Forest Classification Report:\\n\", report_rf)\n",
    "print(\"SVM Classification Report:\\n\", report_svm)\n",
    "print(\"k-NN Classification Report:\\n\", report_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and save the confusion matrix for Random Forest\n",
    "def plot_confusion_matrixPercentage(true_labels, pred_labels, class_names):\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    \n",
    "    # Normalize by the number of true labels in each row to get percentages\n",
    "    cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100  # Convert to percentage\n",
    "    cm_percentage = np.nan_to_num(cm_percentage)  # Replace NaN with 0 if division by zero occurs\n",
    "\n",
    "    # Create custom annotations with percentage symbol\n",
    "    annotations = np.array([[f'{int(value)}%' for value in row] for row in cm_percentage])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))  \n",
    "    sns.heatmap(cm_percentage, annot=annotations, fmt=\"\", cmap=\"Blues\", \n",
    "                xticklabels=class_names, yticklabels=class_names, cbar=False)\n",
    "    \n",
    "    plt.title(\"Confusion Matrix (Percentage)\", fontsize=16)\n",
    "    plt.xlabel(\"Predicted Labels\", fontsize=12)\n",
    "    plt.ylabel(\"True Labels\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "class_names = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']   \n",
    "plot_confusion_matrixPercentage(y_test, rf_pred, class_names)\n",
    "plot_confusion_matrixPercentage(y_test, svm_pred, class_names)\n",
    "plot_confusion_matrixPercentage(y_test, knn_pred, class_names)\n",
    "\n",
    "# Plot and save sample predictions\n",
    "plt.figure(figsize=(30, 40))\n",
    "for n, i in enumerate(list(np.random.randint(0, len(X_test), 36))):\n",
    "    plt.subplot(6, 6, n+1)\n",
    "    plt.imshow(X_test[i])\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Actual: {getcode(y_test[i])}\\n Predict: {getcode(rf_pred[i])}', fontdict={'fontsize': 14, 'color': 'blue'})\n",
    "plt.savefig('imagePrediction.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Accuracy: 0.556\n",
    "\n",
    "#### Random Forest Classification Report:\n",
    "\n",
    "| Class      | Precision | Recall | F1-Score | Support |\n",
    "|------------|------------|--------|----------|---------|\n",
    "| buildings  | 0.44       | 0.33   | 0.38     | 437     |\n",
    "| forest     | 0.66       | 0.79   | 0.72     | 474     |\n",
    "| glacier    | 0.54       | 0.58   | 0.56     | 553     |\n",
    "| mountain   | 0.54       | 0.63   | 0.58     | 525     |\n",
    "| sea        | 0.52       | 0.35   | 0.41     | 510     |\n",
    "| street     | 0.58       | 0.64   | 0.61     | 501     |\n",
    "| **accuracy** | **0.56** |        |          | 3000    |\n",
    "| macro avg  | 0.55       | 0.55   | 0.54     | 3000    |\n",
    "| weighted avg | 0.55     | 0.56   | 0.55     | 3000    |\n",
    "\n",
    "### k-NN Accuracy: 0.400\n",
    "\n",
    "#### k-NN Classification Report:\n",
    "\n",
    "| Class      | Precision | Recall | F1-Score | Support |\n",
    "|------------|------------|--------|----------|---------|\n",
    "| buildings  | 0.33       | 0.03   | 0.05     | 437     |\n",
    "| forest     | 0.58       | 0.66   | 0.62     | 474     |\n",
    "| glacier    | 0.47       | 0.45   | 0.46     | 553     |\n",
    "| mountain   | 0.34       | 0.74   | 0.46     | 525     |\n",
    "| sea        | 0.26       | 0.33   | 0.29     | 510     |\n",
    "| street     | 0.71       | 0.14   | 0.24     | 501     |\n",
    "| **accuracy** | **0.40** |        |          | 3000    |\n",
    "| macro avg  | 0.45       | 0.39   | 0.35     | 3000    |\n",
    "| weighted avg | 0.45     | 0.40   | 0.36     | 3000    |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
